---
title: "P8103 Homework 3"
author: "Adina Zhang"
duedate: "October 15, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(p8105.datasets)
library(ggplot2)
library(tidyr)
library(patchwork)

```

## Problem 1

#### Set up BRFSS dataset

```{r BRFSS_df}
# Load and clean BRFSS dataset
brfss_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(year, locationabbr, locationdesc, response, data_value) %>% 
  mutate(response = factor(response,
                           levels = c("Excellent", "Very good", "Good", "Fair", "Poor"))) 

brfss_df
```

#### Subset the dataset into number of locations per state in 2002

```{r count_location}
# Subset brfss dataset to count number of locations in each state
filter(brfss_df, year == 2002) %>% 
  distinct(locationabbr, locationdesc) %>% 
  group_by(locationabbr) %>% 
  count() %>% 
  filter(n == 7) %>% 
  knitr::kable()
  
```

In 2002, there were three states (CT, FL, and NC) that observed seven locations. 

#### Spaghetti plot

```{r spaghetti_plot}
# Separate dataset into spaghetti plot variables
spaghetti_plot = brfss_df %>% 
  distinct(locationabbr, locationdesc, year) %>% 
  group_by(locationabbr, year) %>% 
  summarize(n = n())

# Create spaghetti_plot 
spaghetti_plot %>% 
  ggplot(aes(x = year, y = n)) +
  geom_line(aes(color = locationabbr)) +
  viridis::scale_color_viridis(
    name = "Location", 
    discrete = TRUE
  ) + 
  labs(
    title = "Number of locations by state, 2002-2010",
    x = "Year",
    y = "Number of Locations",
    caption = "BRFSS Dataset"
  ) + 
  theme(legend.position = "none")

```

#### Descriptive variables for "Excellent" proportions in 2002, 2006, and 2010

```{r brfss_table}
# Summarize descriptive variables to make a table
brfss_df %>% 
  filter(year %in% c(2002, 2006, 2010), response == "Excellent") %>% 
  group_by(year) %>% 
  summarize(mean_excellent = mean(data_value, na.rm = TRUE),
            std_excellent = sd(data_value, na.rm = TRUE)) %>% 
  knitr::kable()
```

#### Five-panel plot, distribution of responses

```{r response_df}
# Summarize average proportions of each response 
response_df = brfss_df %>% 
  group_by(year, locationabbr, response) %>% 
  summarize(mean_prop = mean(data_value, na.rm = TRUE))

# Plot distributions in five panels
response_df %>% 
  ggplot(aes(x = year, y = mean_prop)) + 
  geom_line(aes(color = locationabbr)) + 
  facet_grid(.~response) + 
  labs(
    title = "Distribution of response proportions by state-level, 2002-2010",
    x = "Year",
    y = "State level averages",
    caption = "BRFSS dataset"
  ) + 
  viridis::scale_color_viridis(
    name = "Location", 
    discrete = TRUE
  ) + 
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60))

```

## Problem 2

#### Instacart summary

```{r instacart_df}
# Load instacard
instacart_df = instacart

instacart_df
```

Instacart is an online grocery shopping company, and the instacard dataset contains information on online grocery orders from their customers. The instacart dataset includes `r nrow(instacart_df)` observations and `r ncol(instacart_df)` variables. Some of these key variables include product name, food aisle information (name, number, department), time or order (day of the week, hour of the day, days since last ordered). For example, there are `r nrow(distinct(instacart_df, instacart_df$department))` departments which range from snacks, frozen foods, to dairy and eggs... 

#### Aisle information

There are `r nrow(distinct(instacart_df, aisle))` aisles in this dataset. Some examples of these include yogurt, fresh vegetables, and specialty cheeses. The aisle with the most counts of order. Most items are ordered from the fresh vegetable, fresh fruit, and packaged vegetables and fruits aisles. 
 
```{r aisle_count}
# Group by aisles and summarize counts
aisle_count = instacart_df %>% 
  group_by(aisle, department) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n)) 
  
aisle_count
```

**Aisle Count Plot**

```{r plot_aisle_count, fig.height = 15}
# Plot distribution of items ordered from each aisle
ggplot(aisle_count, aes(x = log(n), y = aisle)) +
  geom_point(aes(color = department)) + 
  facet_grid(rows = vars(department), scales = "free", space = "free") + 
  labs(
    title = "Number of items ordered by aisle",
    x = "Number of items ordered (log(n))",
    y = "Aisle name"
  ) + 
  theme(axis.ticks = element_blank(), 
        legend.position = "none",
        axis.text.y = element_text(size = 7)) 

```

#### Popular aisle items

```{r popular_product_table}
# Subset and group instacart_df to products of interest
# Count products and then rank them to see most popular purchases
instacart_df %>% 
  filter(aisle %in% c("baking ingredients", 
                      "dog food care", 
                      "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(n = n()) %>% 
  mutate(product_rank = min_rank(desc(n))) %>% 
  filter(product_rank == 1) %>% 
  knitr::kable()
```

#### Average time of day

```{r avgtime_table}
# Subset instacart data to products of interest and times
# Summarize average hour of the day and spread dataset into table format
instacart_df %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  select(product_name, order_hour_of_day, order_dow) %>% 
  group_by(order_dow, product_name) %>% 
  summarize(mean_hour = mean(order_hour_of_day, na.rm = TRUE)) %>% 
  spread(key = product_name, value = mean_hour) %>% 
  knitr::kable()

```
  
This table depicts the average time of day (Sunday through Saturday) customers ordered coffee ice cream and pink lady apples. Note that the week days begin with Sunday (0) and progress to Saturday (6). Based off of this table, people usual buy coffee ice cream in the afternoons with the earliest average time at 12.26 hours on Friday and the latest average time at 15.38 hours on Tuesday. People usually buy Pink Lady Apples at mid-day with the earliest average time at 11.36 hours on Monday and the latest average time at 14.25 hours on Wednesday.


## Problem 3

#### NY NOAA Summary

```{r ny_noaa_df}
# Load NY NOAA Summary and clean
ny_noaa_df = ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(year = as.integer(year),
         month = as.integer(month),
         day = as.integer(day),
         tmax = as.integer(tmax)/10,
         tmin = as.integer(tmin)/10)

ny_noaa_df
```

In this dataset, r length((rowSums(is.na(ny_noaa_df))))/nrow(ny_noaa_df)` of observations have missing variables. 

#### Maximum temperature

```{r tmax_plot, error = FALSE, message = FALSE}
tmax_plot = ny_noaa_df %>%
  filter(month %in% c(1, 7), !(is.na(tmax))) %>% 
  group_by(id, year, month) %>% 
  summarize(mean_max_temp = mean(tmax, na.rm = TRUE))

tmax_plot %>% 
  ggplot(aes(x = year, y = mean_max_temp)) + 
  geom_line(aes(color = id)) + 
  geom_smooth(se = FALSE) + 
  facet_grid(.~month) + 
  theme(legend.position = "none") + 
  viridis::scale_color_viridis(
    name = "Location", 
    discrete = TRUE
  ) + 
  labs(
    title = "Average weather station maximum temperatures in January and July, 1980 - 2010",
    x = "Year",
    y = "Average maximum temperature (deg C)",
    caption = "NY NOAA Dataset"
  )
```


#### Two panel temperature and snowfall plots

```{r two_panel_temp_snowfall}
# Create a hexplot to compare tmin and tmax
noaa_hexplot = ny_noaa_df %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_hex() + 
  labs(
    x = "Minimum temperature (deg C)",
    y = "Maximum temperature (deg C)"
  )

# Create a barplot of snowfall by year
noaa_barplot = ny_noaa_df %>% 
  filter(snow > 0 & snow < 100) %>% 
  ggplot(aes(x = year, y = snow)) + 
  geom_boxplot(aes(group = year)) + 
  coord_flip() + 
  labs(
    x = "Year",
    y = "Snowfall (mm)"
    )

noaa_hexplot + noaa_barplot
```

